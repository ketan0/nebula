<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2022-04-07 Thu 04:35 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>compositionality</title>
<meta name="author" content="Ketan Agrawal" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="syntax.css" />
<link rel="stylesheet" type="text/css" href="styles.css" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
<link rel="manifest" href="/site.webmanifest" />
</head>
<body>
<div id="preamble" class="status">
<header>
    <script src="setup-initial-theme.js"></script>
    <div style="display: flex; flex-direction: row; justify-content: space-between; align-items: center;">
        <a style="color: inherit; text-decoration: none" href="/">
            <svg id="nebula-logo" x="0px" y="0px" width="50px"
                 viewBox="0 0 290.513 290.513" style="enable-background:new 0 0 290.513 290.513;" xml:space="preserve">
                <g>
                    <g>
                        <path d="M168.684,103.086c-58.679,0-93.713,17.515-93.713,46.857c0,18.344,27.214,28.114,46.857,28.114
                                 c46.327,0,46.857-22.472,46.857-23.428l-9.367-0.141c-0.009,0.141-1.354,14.198-37.49,14.198
                                 c-16.976,0-37.485-8.359-37.485-18.743c0-23.124,32.317-37.485,84.342-37.485c68.312,0,112.456,20.233,112.456,51.542
                                 c0,32.818-50.989,70.252-145.49,74.975l0.469,9.357c101.36-5.065,154.393-46.262,154.393-84.333
                                 C290.511,126.996,242.689,103.086,168.684,103.086z"/>
                        <path d="M215.541,154.628c0-18.344-27.214-28.114-46.857-28.114c-46.327,0-46.857,22.472-46.857,23.428
                                 l9.367,0.141c0.009-0.141,1.354-14.198,37.49-14.198c16.976,0,37.485,8.359,37.485,18.743c0,23.124-32.317,37.485-84.342,37.485
                                 c-68.312,0-112.456-20.233-112.456-51.542c0-32.818,50.989-70.252,145.49-74.975l-0.469-9.357C53.032,61.303,0,102.5,0,140.571
                                 c0,37.003,47.822,60.914,121.827,60.914C180.506,201.485,215.541,183.97,215.541,154.628z"/>
                        <path d="M51.542,107.771c0,7.75-6.307,14.057-14.057,14.057v9.371c7.75,0,14.057,6.307,14.057,14.057h9.371
                                 c0-7.75,6.307-14.057,14.057-14.057v-9.371c-7.75,0-14.057-6.307-14.057-14.057H51.542z M56.228,131.214
                                 c-1.335-1.776-2.919-3.364-4.7-4.7c1.781-1.335,3.364-2.924,4.7-4.7c1.335,1.776,2.919,3.364,4.7,4.7
                                 C59.147,127.849,57.563,129.438,56.228,131.214z"/>
                        <path d="M238.969,187.428h9.371c0-10.337,8.406-18.743,18.743-18.743v-9.371
                                 c-10.337,0-18.743-8.406-18.743-18.743h-9.371c0,10.337-8.406,18.743-18.743,18.743v9.371
                                 C230.563,168.685,238.969,177.091,238.969,187.428z M243.655,156.095c2.08,3.13,4.775,5.82,7.905,7.905
                                 c-3.13,2.08-5.82,4.775-7.905,7.905c-2.08-3.13-4.775-5.82-7.905-7.905C238.88,161.919,241.574,159.225,243.655,156.095z"/>
                        <path d="M103.085,206.17h-9.371c0,10.337-8.406,18.743-18.743,18.743v9.371
                                 c10.337,0,18.743,8.406,18.743,18.743h9.371c0-10.337,8.406-18.743,18.743-18.743v-9.371
                                 C111.491,224.913,103.085,216.507,103.085,206.17z M98.399,237.503c-2.08-3.13-4.775-5.82-7.905-7.905
                                 c3.13-2.08,5.82-4.775,7.905-7.905c2.08,3.13,4.775,5.82,7.905,7.905C103.174,231.679,100.479,234.373,98.399,237.503z"/>
                        <path d="M182.741,84.343h9.371c0-10.337,8.406-18.743,18.743-18.743v-9.371
                                 c-10.337,0-18.743-8.406-18.743-18.743h-9.371c0,10.337-8.406,18.743-18.743,18.743V65.6
                                 C174.335,65.6,182.741,74.006,182.741,84.343z M187.427,53.01c2.08,3.13,4.775,5.82,7.905,7.905
                                 c-3.13,2.08-5.82,4.775-7.905,7.905c-2.08-3.13-4.775-5.82-7.905-7.905C182.652,58.834,185.346,56.14,187.427,53.01z"/>
                        <rect x="98.399" y="135.885" width="9.371" height="9.371"/>
                        <rect x="107.77" y="149.942" width="9.371" height="9.371"/>
                        <rect x="168.684" y="168.685" width="9.371" height="9.371"/>
                        <rect x="182.741" y="145.257" width="9.371" height="9.371"/>
		                    <rect x="215.541" y="187.428" width="9.371" height="9.371"/>
		                    <rect x="154.627" y="215.542" width="9.371" height="9.371"/>
	                  </g>
                </g>
            </svg>
        </a>
        <div>
            <input type="checkbox" id="theme-switcher">
            <label id="theme-switcher-label" for="theme-switcher"></label>
        </div>
    </div>
</header>
</div>
<div id="content" class="content">
<h1 class="title">compositionality
<br />
<span class="subtitle">Last modified on April 07, 2022</span>
</h1>
<p>
You have a set of reusable pieces that can be combined to form different, interesting things.<br />
</p>

<p>
Decomposition of <a href="programming.html#ID-0997b060-ee05-458e-beed-3494675c879d">programs</a> into modular, reusable unit is one example of this.<br />
</p>


<div id="orga031df9" class="figure">
<p><img src="decomposition.jpg" alt="Static, Dynamic, and Requirements Models for Systems Partition (as an example of decomposition in programming.)" width="250" /><br />
</p>
</div>

<p>
Some methodical activities, such as making breakfast, decompose well into modular activities as well:<br />
</p>

<div id="org4f5547f" class="figure">
<p><img src="breakfast.png" alt="tree of the decomposition of making breakfast into &quot;make toast,&quot; &quot;make tea,&quot; etc." /><br />
</p>
</div>

<p>
A <a href="machine_learning.html#ID-5b02540a-15ac-4123-86f8-e6ca5420ce27">machine learning</a> example of compositionaity is that a <a href="computer_vision.html#ID-27d08270-d161-4bb1-8b39-50f28b1ab668">computer vision</a> model's early layers will implement an edge detector, curve detector, etc., which are modular pieces that are then combined in various ways by higher-level layers to form dog detectors, car detectors, etc.<br />
</p>


<div id="orgb534ce7" class="figure">
<p><img src="cnnlayers.jpg" alt="progression from low-level to high-level features in a CNN." /><br />
</p>
</div>


<div id="outline-container-org212e118" class="outline-2 references">
<h2 id="org212e118">Links to this node</h2>
<div class="outline-text-2" id="text-org212e118">
</div>
<div id="outline-container-orgc38f595" class="outline-3">
<h3 id="orgc38f595"><a href="counterfactual_generative_networks.html#ID-22706d1f-6b5c-4c77-acc2-d8c222b395d5">Counterfactual Generative Networks</a></h3>
<div class="outline-text-3" id="text-orgc38f595">
<p>
(, )<br />
</p>

<p>
<a href="neural_networks_like_to_cheat.html#ID-412cda14-f385-463d-9a7e-cd9ffe87c0a2">Neural networks like to "cheat"</a> by using simple correlations that fail to generalize. E.g., image classifiers can learn spurious correlations with texture in the background, rather than the actual object's shape; a classifier might learn that "green grass background" =&gt; "cow classification."<br />
</p>

<p>
This work <a href="compositionality.html#ID-b6fafba6-8e57-400d-962c-bf7cc892a41f">decomposes</a> the image generation process into three independent causal mechanisms &#x2013; shape, texture, and background. Thus, one can generate "<a href="causal_inference.html#ID-1f3f1a31-ff89-4c05-8c82-64888887f45e">counterfactual</a> images" to improve OOD robustness, e.g. by placing a cow on a swimming pool background. Related: <a href="private/20200928215821-psych_204.html#ID-8e87ac0e-1002-474e-b4e7-778d908270a6">generative models</a> <a href="causal_inference.html#ID-1f3f1a31-ff89-4c05-8c82-64888887f45e">counterfactuals</a><br />
</p>
</div>
</div>

<div id="outline-container-org492eabb" class="outline-3">
<h3 id="org492eabb"><a href="towards_causal_representation_learning.html#ID-12dfdb1e-d4ed-476b-be04-98cae7a3deaf">Towards Causal Representation Learning</a></h3>
<div class="outline-text-3" id="text-org492eabb">
<p>
(, a)<br />
</p>

<p>
Yoshua Bengio <a href="https://www.youtube.com/watch?v=rKZJ0TJWvTk">talk</a>. Also, the associated <a href="https://arxiv.org/abs/2102.11107">paper</a>.<br />
</p>

<p>
causal representation learning: the discovery of high-level causal variables from low-level observations.<br />
</p>

<p>
In practice, i.i.d. is a bad assumption. Things don't stay the same distribution as train. Current DL systems are brittle.<br />
</p>

<p>
But&#x2026;what assumption can we replace it with, then?<br />
</p>

<p>
how does the brain break knowledge apart into "pieces" that can be reused? =&gt; <a href="compositionality.html#ID-b6fafba6-8e57-400d-962c-bf7cc892a41f">compositionality</a> (thinking decomposition into helper functions in programming.) Examples of compositionality include<br />
</p>
</div>
</div>

<div id="outline-container-org466aad0" class="outline-3">
<h3 id="org466aad0"><a href="notes_i_m_actively_working_on.html#ID-4bba82cd-9443-4496-8896-81323093ec11">notes I'm actively working on</a></h3>
<div class="outline-text-3" id="text-org466aad0">
<p>
<a href="notes_i_m_actively_working_on.html#ID-4bba82cd-9443-4496-8896-81323093ec11">notes I'm actively working on</a> (hah, recursive)<br />
<a href="code_comments.html#ID-3f0de91d-119f-4fd2-942e-f3458e60ed40">code comments</a><br />
<a href="book_notes.html#ID-b910e58f-f1fe-4c3f-8efb-69bfa261b191">üìö book notes</a><br />
<a href="game_of_life.html#ID-918b7900-d37d-4d92-a900-6d6632fd2f47">üî≤ Conway's Game of Life</a><br />
<a href="philosophy.html#ID-091329e5-7896-4975-b88b-99b30f4dd482">üßê philosophy</a><br />
<a href="rules_of_thumb.html#ID-5df9203d-c7d9-4341-b7dc-ac4236000d8b">rules of thumb</a><br />
<a href="compositionality.html#ID-b6fafba6-8e57-400d-962c-bf7cc892a41f">decomposition</a><br />
<a href="don_t_repeat_yourself_dry_works_well_for_code_not_people.html#ID-e2a95a21-0e55-4160-a6bb-0d7f87e81516">Don't Repeat Yourself (DRY) works well for code, not people.</a><br />
<a href="blog_posts.html#ID-288afdae-8e50-4aa5-b16f-2545baf10967">blog posts</a><br />
</p>
</div>
</div>
</div>



<div id="outline-container-orgbb1d9a5" class="outline-2 references">
<h2 id="orgbb1d9a5">Links to this node</h2>
<div class="outline-text-2" id="text-orgbb1d9a5">
</div>
<div id="outline-container-org8b03568" class="outline-3">
<h3 id="org8b03568"><a href="counterfactual_generative_networks.html#ID-22706d1f-6b5c-4c77-acc2-d8c222b395d5">Counterfactual Generative Networks</a></h3>
<div class="outline-text-3" id="text-org8b03568">
<p>
(, )<br />
</p>

<p>
<a href="neural_networks_like_to_cheat.html#ID-412cda14-f385-463d-9a7e-cd9ffe87c0a2">Neural networks like to "cheat"</a> by using simple correlations that fail to generalize. E.g., image classifiers can learn spurious correlations with texture in the background, rather than the actual object's shape; a classifier might learn that "green grass background" =&gt; "cow classification."<br />
</p>

<p>
This work <a href="compositionality.html#ID-b6fafba6-8e57-400d-962c-bf7cc892a41f">decomposes</a> the image generation process into three independent causal mechanisms &#x2013; shape, texture, and background. Thus, one can generate "<a href="causal_inference.html#ID-1f3f1a31-ff89-4c05-8c82-64888887f45e">counterfactual</a> images" to improve OOD robustness, e.g. by placing a cow on a swimming pool background. Related: <a href="private/20200928215821-psych_204.html#ID-8e87ac0e-1002-474e-b4e7-778d908270a6">generative models</a> <a href="causal_inference.html#ID-1f3f1a31-ff89-4c05-8c82-64888887f45e">counterfactuals</a><br />
</p>
</div>
</div>

<div id="outline-container-orga7694a5" class="outline-3">
<h3 id="orga7694a5"><a href="towards_causal_representation_learning.html#ID-12dfdb1e-d4ed-476b-be04-98cae7a3deaf">Towards Causal Representation Learning</a></h3>
<div class="outline-text-3" id="text-orga7694a5">
<p>
(, a)<br />
</p>

<p>
Yoshua Bengio <a href="https://www.youtube.com/watch?v=rKZJ0TJWvTk">talk</a>. Also, the associated <a href="https://arxiv.org/abs/2102.11107">paper</a>.<br />
</p>

<p>
causal representation learning: the discovery of high-level causal variables from low-level observations.<br />
</p>

<p>
In practice, i.i.d. is a bad assumption. Things don't stay the same distribution as train. Current DL systems are brittle.<br />
</p>

<p>
But&#x2026;what assumption can we replace it with, then?<br />
</p>

<p>
how does the brain break knowledge apart into "pieces" that can be reused? =&gt; <a href="compositionality.html#ID-b6fafba6-8e57-400d-962c-bf7cc892a41f">compositionality</a> (thinking decomposition into helper functions in programming.) Examples of compositionality include<br />
</p>
</div>
</div>

<div id="outline-container-orged39c53" class="outline-3">
<h3 id="orged39c53"><a href="notes_i_m_actively_working_on.html#ID-4bba82cd-9443-4496-8896-81323093ec11">notes I'm actively working on</a></h3>
<div class="outline-text-3" id="text-orged39c53">
<p>
<a href="notes_i_m_actively_working_on.html#ID-4bba82cd-9443-4496-8896-81323093ec11">notes I'm actively working on</a> (hah, recursive)<br />
<a href="code_comments.html#ID-3f0de91d-119f-4fd2-942e-f3458e60ed40">code comments</a><br />
<a href="book_notes.html#ID-b910e58f-f1fe-4c3f-8efb-69bfa261b191">üìö book notes</a><br />
<a href="game_of_life.html#ID-918b7900-d37d-4d92-a900-6d6632fd2f47">üî≤ Conway's Game of Life</a><br />
<a href="philosophy.html#ID-091329e5-7896-4975-b88b-99b30f4dd482">üßê philosophy</a><br />
<a href="rules_of_thumb.html#ID-5df9203d-c7d9-4341-b7dc-ac4236000d8b">rules of thumb</a><br />
<a href="compositionality.html#ID-b6fafba6-8e57-400d-962c-bf7cc892a41f">decomposition</a><br />
<a href="don_t_repeat_yourself_dry_works_well_for_code_not_people.html#ID-e2a95a21-0e55-4160-a6bb-0d7f87e81516">Don't Repeat Yourself (DRY) works well for code, not people.</a><br />
<a href="blog_posts.html#ID-288afdae-8e50-4aa5-b16f-2545baf10967">blog posts</a><br />
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<footer>
  <p>Made with <span class="heart">‚ô•</span> using
    <a href="https://orgmode.org/">org-mode</a>.
    Source code is available
    <a href="https://github.com/ketan0/digital-laboratory">here</a>.
  </p>
</footer>
<script src="popper.min.js"></script>
<script src="tippy-bundle.umd.min.js"></script>
<script src="tooltips.js"></script>
<script src="setup-theme-switcher.js"></script>
<script src="dark-themes.js"></script>
</div>
</body>
</html>
