<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-07-26 Sat 11:48 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Neural networks like to "cheat"</title>
<meta name="author" content="Ketan Agrawal" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="syntax.css" />
<link rel="stylesheet" type="text/css" href="styles.css" />
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
<link rel="manifest" href="/site.webmanifest" />
</head>
<body>
<div id="preamble" class="status">
<header>
    <script src="setup-initial-theme.js"></script>
    <nav style="display: flex; justify-content: space-between; align-items: center;">
        <a href="/" style="color: inherit; text-decoration: none;">ketan.me</a>
        <ul style="display: flex; list-style-type: none; padding: 0; margin: 0;">
            <li style="margin-left: 1rem;"><a href="/blog.html">blog</a></li>
            <li style="margin-left: 1rem;"><a href="/thoughts.html">thoughts</a></li>
            <li style="margin-left: 1rem;"><a href="/experiments.html">garden</a></li>
            <li style="margin-left: 1rem;"><input type="checkbox" id="theme-switcher">
                <label id="theme-switcher-label" for="theme-switcher"></label>
            </li>
        </ul>
    </nav>
</header>
</div>
<div id="content" class="content">
<h1 class="title">Neural networks like to &ldquo;cheat&rdquo;
<br />
<span class="subtitle">Last tended to on April 08, 2022</span>
</h1>
<p>
<a href="artificial_intelligence.html#ID-ef80dd22-3ade-4fd6-98cd-1319eaa454f9">artificial intelligence</a><br />
</p>
<div id="outline-container-org2bbbab1" class="outline-2 references">
<h2 id="org2bbbab1">Links to &ldquo;Neural networks like to &rdquo;cheat&ldquo;&rdquo;</h2>
<div class="outline-text-2" id="text-org2bbbab1">
</div>
<div id="outline-container-orgd221917" class="outline-3">
<h3 id="orgd221917"><a href="counterfactual_generative_networks.html#ID-22706d1f-6b5c-4c77-acc2-d8c222b395d5">Counterfactual Generative Networks</a></h3>
<div class="outline-text-3" id="text-orgd221917">
<p>
<a href="neural_networks_like_to_cheat.html#ID-412cda14-f385-463d-9a7e-cd9ffe87c0a2">Neural networks like to &ldquo;cheat&rdquo;</a> by using simple correlations that fail to generalize. E.g., image classifiers can learn spurious correlations with texture in the background, rather than the actual object&rsquo;s shape; a classifier might learn that &ldquo;green grass background&rdquo; =&gt; &ldquo;cow classification.&rdquo;<br />
</p>

<p>
This work <a href="compositionality.html#ID-b6fafba6-8e57-400d-962c-bf7cc892a41f">decomposes</a> the image generation process into three independent causal mechanisms &#x2013; shape, texture, and background. Thus, one can generate &ldquo;<a href="causal_inference.html#ID-1f3f1a31-ff89-4c05-8c82-64888887f45e">counterfactual</a> images&rdquo; to improve OOD robustness, e.g. by placing a cow on a swimming pool background. Related: <a href="private/20200928215821-psych_204.html#ID-8e87ac0e-1002-474e-b4e7-778d908270a6">generative models</a> <a href="causal_inference.html#ID-1f3f1a31-ff89-4c05-8c82-64888887f45e">counterfactuals</a><br />
</p>
</div>
</div>
<div id="outline-container-org5c48f52" class="outline-3">
<h3 id="org5c48f52"><a href="cs224u_natural_language_understanding.html#ID-4785205d-bb3f-4795-9b13-7bc8128e3ae0">CS224u: Natural Language Understanding</a> <span class="backlinks-outline-path">(<i>Introduction &gt; Limitations</i>)</span></h3>
<div class="outline-text-3" id="text-org5c48f52">
<ul class="org-ul">
<li>NLU systems are easily &ldquo;confused.&rdquo;<br /></li>
<li>Models don&rsquo;t &ldquo;know what the world is like.&rdquo; e.g., GPT-3 doesn&rsquo;t really&#x2026;know what a cat is. Image-captioning models show that they don&rsquo;t know what the world is like.<br /></li>
<li>Systems can encourage self-harm.<br /></li>
<li>Systems are vulnerable to adversarial attacks.<br /></li>
<li>Social biases are reflected in NLP models.<br /></li>
<li>Observing diminishing returns in ever-larger language models.<br /></li>
<li><a href="neural_networks_like_to_cheat.html#ID-412cda14-f385-463d-9a7e-cd9ffe87c0a2">Neural networks like to &ldquo;cheat&rdquo;.</a> NLI models figure out how to predict the correct relation between premise-hypothesis through some superficial correlation.<br /></li>
</ul>

<p>
Question someone asked: &ldquo;Is there any case where symbolic approaches definitely would be used over neural nets?&rdquo;<br />
</p>

<p>
Answer: Mental health chatbot. Don&rsquo;t want it saying harmful things to users. Other safety-critical situations. etc. Also&#x2013; sometimes a mixture of symbolic and neural approaches, e.g. how in Google Translate, they may tack on a logical rule that attempts to correct for gender biases in neurally-produced translations.<br />
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<!-- copyright Ketan agrawal - on line below-->
<p>&copy; Ketan Agrawal, 2024. <a href="https://x.com/_ketan0">@_ketan0</a>.</p>
<script src="popper.min.js"></script>
<script src="tippy-bundle.umd.min.js"></script>
<script src="tooltips.js"></script>
<script src="setup-theme-switcher.js"></script>
<script src="insert-intext-citation.js"></script>
</div>
</body>
</html>
